"""
Dashboard interactivo profesional para predicci√≥n y optimizaci√≥n de recursos contra incendios
Usa datos reales de CONAF con filtros interactivos para investigadores
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import re
try:
    import folium
    from streamlit_folium import folium_static
    FOLIUM_AVAILABLE = True
except ImportError:
    FOLIUM_AVAILABLE = False
from pathlib import Path
import sys

# Agregar src al path
sys.path.append(str(Path(__file__).parent))

# Mapeo completo de comunas a regiones (basado en divisi√≥n administrativa oficial de Chile)
MAPEO_COMUNA_REGION = {
    # XV de Arica y Parinacota
    'Arica': 'XV', 'Camarones': 'XV', 'Putre': 'XV', 'General Lagos': 'XV',
    # I de Tarapac√°
    'Alto Hospicio': 'I', 'Iquique': 'I', 'Huara': 'I', 'Cami√±a': 'I', 'Colchane': 'I', 
    'Pica': 'I', 'Pozo Almonte': 'I',
    # II de Antofagasta
    'Tocopilla': 'II', 'Mar√≠a Elena': 'II', 'Calama': 'II', 'Ollag√ºe': 'II', 
    'San Pedro de Atacama': 'II', 'Antofagasta': 'II', 'Mejillones': 'II', 
    'Sierra Gorda': 'II', 'Taltal': 'II',
    # III de Atacama
    'Cha√±aral': 'III', 'Diego de Almagro': 'III', 'Copiap√≥': 'III', 'Caldera': 'III', 
    'Tierra Amarilla': 'III', 'Vallenar': 'III', 'Freirina': 'III', 'Huasco': 'III', 
    'Alto del Carmen': 'III',
    # IV de Coquimbo
    'La Serena': 'IV', 'La Higuera': 'IV', 'Coquimbo': 'IV', 'Andacollo': 'IV', 
    'Vicu√±a': 'IV', 'Paihuano': 'IV', 'Ovalle': 'IV', 'R√≠o Hurtado': 'IV', 
    'Monte Patria': 'IV', 'Combarbal√°': 'IV', 'Punitaqui': 'IV', 'Illapel': 'IV', 
    'Salamanca': 'IV', 'Los Vilos': 'IV', 'Canela': 'IV',
    # V de Valpara√≠so
    'La Ligua': 'V', 'Petorca': 'V', 'Cabildo': 'V', 'Zapallar': 'V', 'Papudo': 'V', 
    'Los Andes': 'V', 'San Esteban': 'V', 'Calle Larga': 'V', 'Rinconada': 'V', 
    'San Felipe': 'V', 'Putaendo': 'V', 'Santa Mar√≠a': 'V', 'Panquehue': 'V', 
    'Llaillay': 'V', 'Catemu': 'V', 'Quillota': 'V', 'La Cruz': 'V', 'Calera': 'V', 
    'Nogales': 'V', 'Hijuelas': 'V', 'Limache': 'V', 'Olmu√©': 'V', 'Valpara√≠so': 'V', 
    'Vi√±a del Mar': 'V', 'Quintero': 'V', 'Puchuncav√≠': 'V', 'Quilpu√©': 'V', 
    'Villa Alemana': 'V', 'Casablanca': 'V', 'Conc√≥n': 'V', 'Juan Fern√°ndez': 'V', 
    'San Antonio': 'V', 'Cartagena': 'V', 'El Tabo': 'V', 'El Quisco': 'V', 
    'Algarrobo': 'V', 'Santo Domingo': 'V', 'Isla de Pascua': 'V',
    # VI del Libertador General Bernardo O'Higgins
    'Rancagua': 'VI', 'Graneros': 'VI', 'Mostazal': 'VI', 'Codegua': 'VI', 
    'Machal√≠': 'VI', 'Olivar': 'VI', 'Requinoa': 'VI', 'Rengo': 'VI', 'Malloa': 'VI', 
    'Quinta de Tilcoco': 'VI', 'San Vicente': 'VI', 'Pichidegua': 'VI', 'Peumo': 'VI', 
    'Coltauco': 'VI', 'Coinco': 'VI', 'Do√±ihue': 'VI', 'Las Cabras': 'VI', 
    'San Fernando': 'VI', 'Chimbarongo': 'VI', 'Placilla': 'VI', 'Nancagua': 'VI', 
    'Ch√©pica': 'VI', 'Santa Cruz': 'VI', 'Lolol': 'VI', 'Pumanque': 'VI', 
    'Palmilla': 'VI', 'Peralillo': 'VI', 'Pichilemu': 'VI', 'Navidad': 'VI', 
    'Litueche': 'VI', 'La Estrella': 'VI', 'Marchihue': 'VI', 'Paredones': 'VI',
    # VII del Maule
    'Curic√≥': 'VII', 'Teno': 'VII', 'Romeral': 'VII', 'Molina': 'VII', 
    'Sagrada Familia': 'VII', 'Huala√±√©': 'VII', 'Licant√©n': 'VII', 'Vichuqu√©n': 'VII', 
    'Rauco': 'VII', 'Talca': 'VII', 'Pelarco': 'VII', 'R√≠o Claro': 'VII', 
    'San Clemente': 'VII', 'Maule': 'VII', 'San Rafael': 'VII', 'Empedrado': 'VII', 
    'Pencahue': 'VII', 'Constituci√≥n': 'VII', 'Curepto': 'VII', 'Linares': 'VII', 
    'Yerbas Buenas': 'VII', 'Colb√∫n': 'VII', 'Longav√≠': 'VII', 'Parral': 'VII', 
    'Retiro': 'VII', 'Villa Alegre': 'VII', 'San Javier': 'VII', 'Cauquenes': 'VII', 
    'Pelluhue': 'VII', 'Chanco': 'VII',
    # VIII del Biob√≠o
    'Chill√°n': 'VIII', 'San Carlos': 'VIII', '√ëiqu√©n': 'VIII', 'San Fabi√°n': 'VIII', 
    'Coihueco': 'VIII', 'Pinto': 'VIII', 'San Ignacio': 'VIII', 'El Carmen': 'VIII', 
    'Yungay': 'VIII', 'Pemuco': 'VIII', 'Bulnes': 'VIII', 'Quill√≥n': 'VIII', 
    'R√°nquil': 'VIII', 'Portezuelo': 'VIII', 'Coelemu': 'VIII', 'Treguaco': 'VIII', 
    'Cobquecura': 'VIII', 'Quirihue': 'VIII', 'Ninhue': 'VIII', 'San Nicol√°s': 'VIII', 
    'Chill√°n Viejo': 'VIII', 'Alto Biob√≠o': 'VIII', 'Los Angeles': 'VIII', 
    'Los √Ångeles': 'VIII', 'Cabrero': 'VIII', 'Tucapel': 'VIII', 'Antuco': 'VIII', 
    'Quilleco': 'VIII', 'Santa B√°rbara': 'VIII', 'Quilaco': 'VIII', 'Mulch√©n': 'VIII', 
    'Negrete': 'VIII', 'Nacimiento': 'VIII', 'Laja': 'VIII', 'San Rosendo': 'VIII', 
    'Yumbel': 'VIII', 'Concepci√≥n': 'VIII', 'Talcahuano': 'VIII', 'Penco': 'VIII', 
    'Tom√©': 'VIII', 'Florida': 'VIII', 'Hualp√©n': 'VIII', 'Hualqui': 'VIII', 
    'Santa Juana': 'VIII', 'Lota': 'VIII', 'Coronel': 'VIII', 'San Pedro de la Paz': 'VIII', 
    'Chiguayante': 'VIII', 'Lebu': 'VIII', 'Arauco': 'VIII', 'Curanilahue': 'VIII', 
    'Los Alamos': 'VIII', 'Los √Ålamos': 'VIII', 'Ca√±ete': 'VIII', 'Contulmo': 'VIII', 
    'Tirua': 'VIII', 'Tir√∫a': 'VIII',
    # IX de la Araucan√≠a
    'Angol': 'IX', 'Renaico': 'IX', 'Collipulli': 'IX', 'Lonquimay': 'IX', 
    'Curacaut√≠n': 'IX', 'Ercilla': 'IX', 'Victoria': 'IX', 'Traigu√©n': 'IX', 
    'Lumaco': 'IX', 'Pur√©n': 'IX', 'Los Sauces': 'IX', 'Temuco': 'IX', 
    'Lautaro': 'IX', 'Perquenco': 'IX', 'Vilc√∫n': 'IX', 'Cholchol': 'IX', 
    'Cunco': 'IX', 'Melipeuco': 'IX', 'Curarrehue': 'IX', 'Puc√≥n': 'IX', 
    'Villarrica': 'IX', 'Freire': 'IX', 'Pitrufqu√©n': 'IX', 'Gorbea': 'IX', 
    'Loncoche': 'IX', 'Tolt√©n': 'IX', 'Teodoro Schmidt': 'IX', 'Saavedra': 'IX', 
    'Carahue': 'IX', 'Nueva Imperial': 'IX', 'Galvarino': 'IX', 'Padre las Casas': 'IX',
    # XIV de los R√≠os
    'Valdivia': 'XIV', 'Mariquina': 'XIV', 'Lanco': 'XIV', 'M√°fil': 'XIV', 
    'Corral': 'XIV', 'Panguipulli': 'XIV', 'Paillaco': 'XIV', 'La Uni√≥n': 'XIV', 
    'Futrono': 'XIV', 'R√≠o Bueno': 'XIV', 'Lago Ranco': 'XIV',
    # X de los Lagos
    'Osorno': 'X', 'San Pablo': 'X', 'Puyehue': 'X', 'Puerto Octay': 'X', 
    'Purranque': 'X', 'R√≠o Negro': 'X', 'San Juan de la Costa': 'X', 
    'Puerto Montt': 'X', 'Puerto Varas': 'X', 'Cocham√≥': 'X', 'Calbuco': 'X', 
    'Maull√≠n': 'X', 'Los Muermos': 'X', 'Fresia': 'X', 'Llanquihue': 'X', 
    'Frutillar': 'X', 'Castro': 'X', 'Ancud': 'X', 'Quemchi': 'X', 'Dalcahue': 'X', 
    'Curaco de V√©lez': 'X', 'Quinchao': 'X', 'Puqueld√≥n': 'X', 'Chonchi': 'X', 
    'Queil√©n': 'X', 'Quell√≥n': 'X', 'Chait√©n': 'X', 'Hualaihu√©': 'X', 
    'Futaleuf√∫': 'X', 'Palena': 'X',
    # XI Ays√©n del General Carlos Ib√°√±ez del Campo
    'Coyhaique': 'XI', 'Lago Verde': 'XI', 'Ays√©n': 'XI', 'Cisnes': 'XI', 
    'Guaitecas': 'XI', 'Chile Chico': 'XI', 'R√≠o Ib√°nez': 'XI', 'Cochrane': 'XI', 
    "O'Higgins": 'XI', 'Tortel': 'XI',
    # XII de Magallanes y Ant√°rtica Chilena
    'Natales': 'XII', 'Torres del Paine': 'XII', 'Punta Arenas': 'XII', 
    'R√≠o Verde': 'XII', 'Laguna Blanca': 'XII', 'San Gregorio': 'XII', 
    'Porvenir': 'XII', 'Primavera': 'XII', 'Timaukel': 'XII', 'Cabo de Hornos': 'XII', 
    'Ant√°rtica': 'XII',
    # Metropolitana de Santiago (RM)
    'Santiago': 'RM', 'Independencia': 'RM', 'Conchal√≠': 'RM', 'Huechuraba': 'RM', 
    'Recoleta': 'RM', 'Providencia': 'RM', 'Vitacura': 'RM', 'Lo Barnechea': 'RM', 
    'Las Condes': 'RM', '√ëu√±oa': 'RM', 'La Reina': 'RM', 'Macul': 'RM', 
    'Pe√±alol√©n': 'RM', 'La Florida': 'RM', 'San Joaqu√≠n': 'RM', 'La Granja': 'RM', 
    'La Pintana': 'RM', 'San Ram√≥n': 'RM', 'San Miguel': 'RM', 'La Cisterna': 'RM', 
    'El Bosque': 'RM', 'Pedro Aguirre Cerda': 'RM', 'Lo Espejo': 'RM', 
    'Estaci√≥n Central': 'RM', 'Cerrillos': 'RM', 'Maip√∫': 'RM', 'Quinta Normal': 'RM', 
    'Lo Prado': 'RM', 'Pudahuel': 'RM', 'Cerro Navia': 'RM', 'Renca': 'RM', 
    'Quilicura': 'RM', 'Colina': 'RM', 'Lampa': 'RM', 'Tiltil': 'RM', 
    'Puente Alto': 'RM', 'San Jos√© de Maipo': 'RM', 'Pirque': 'RM', 
    'San Bernardo': 'RM', 'Buin': 'RM', 'Paine': 'RM', 'Calera de Tango': 'RM', 
    'Melipilla': 'RM', 'Mar√≠a Pinto': 'RM', 'Curacav√≠': 'RM', 'Alhu√©': 'RM', 
    'San Pedro': 'RM', 'Talagante': 'RM', 'Pe√±aflor': 'RM', 'Isla de Maipo': 'RM', 
    'El Monte': 'RM', 'Padre Hurtado': 'RM'
}

# Funci√≥n para obtener regi√≥n de una comuna
def obtener_region_por_comuna(comuna_str):
    """Obtiene la regi√≥n de una comuna usando el mapeo oficial"""
    if pd.isna(comuna_str) or comuna_str == '':
        return None
    
    comuna_normalizada = str(comuna_str).strip().title()
    
    # Buscar coincidencia exacta
    if comuna_normalizada in MAPEO_COMUNA_REGION:
        return MAPEO_COMUNA_REGION[comuna_normalizada]
    
    # Buscar coincidencia sin acentos y con variaciones comunes
    comuna_sin_acentos = comuna_normalizada.replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u').replace('√±', 'n')
    for comuna_key, region in MAPEO_COMUNA_REGION.items():
        comuna_key_sin_acentos = comuna_key.replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u').replace('√±', 'n')
        if comuna_sin_acentos.lower() == comuna_key_sin_acentos.lower():
            return region
    
    return None

# Funci√≥n para normalizar regiones a formato est√°ndar
def normalizar_region(region_str):
    """Normaliza nombres de regiones a formato est√°ndar (I, II, III, ..., XVI, RM)"""
    if pd.isna(region_str) or region_str == '':
        return 'Sin Regi√≥n'
    
    region_str = str(region_str).strip().upper()
    
    # Mapeo de n√∫meros a romanos
    numero_a_romano = {
        '1': 'I', '2': 'II', '3': 'III', '4': 'IV', '5': 'V',
        '6': 'VI', '7': 'VII', '8': 'VIII', '9': 'IX', '10': 'X',
        '11': 'XI', '12': 'XII', '13': 'XIII', '14': 'XIV', '15': 'XV', '16': 'XVI'
    }
    
    # Mapeo de variantes comunes
    variantes = {
        'RM': 'RM', 'REGION METROPOLITANA': 'RM', 'METROPOLITANA': 'RM',
        'METROPOLITANA DE SANTIAGO': 'RM', 'SANTIAGO': 'RM',
        'I': 'I', 'PRIMERA': 'I', 'TARAPACA': 'I', 'TARAPAC√Å': 'I',
        'II': 'II', 'SEGUNDA': 'II', 'ANTOFAGASTA': 'II',
        'III': 'III', 'TERCERA': 'III', 'ATACAMA': 'III',
        'IV': 'IV', 'CUARTA': 'IV', 'COQUIMBO': 'IV',
        'V': 'V', 'QUINTA': 'V', 'VALPARAISO': 'V', 'VALPARA√çSO': 'V',
        'VI': 'VI', 'SEXTA': 'VI', "O'HIGGINS": 'VI', 'OHIGGINS': 'VI',
        'VII': 'VII', 'SEPTIMA': 'VII', 'SEPTIMA': 'VII', 'MAULE': 'VII',
        'VIII': 'VIII', 'OCTAVA': 'VIII', 'BIOBIO': 'VIII', 'B√çOB√çO': 'VIII', 'BIO BIO': 'VIII',
        'IX': 'IX', 'NOVENA': 'IX', 'ARAUCANIA': 'IX', 'ARAUCAN√çA': 'IX',
        'X': 'X', 'DECIMA': 'X', 'D√âCIMA': 'X', 'LOS LAGOS': 'X',
        'XI': 'XI', 'DECIMA PRIMERA': 'XI', 'D√âCIMA PRIMERA': 'XI', 'AYSEN': 'XI', 'AYS√âN': 'XI',
        'XII': 'XII', 'DECIMA SEGUNDA': 'XII', 'D√âCIMA SEGUNDA': 'XII', 'MAGALLANES': 'XII',
        'XIV': 'XIV', 'DECIMA CUARTA': 'XIV', 'D√âCIMA CUARTA': 'XIV', 'LOS RIOS': 'XIV', 'LOS R√çOS': 'XIV',
        'XV': 'XV', 'DECIMA QUINTA': 'XV', 'D√âCIMA QUINTA': 'XV', 'ARICA Y PARINACOTA': 'XV',
        'XVI': 'XVI', 'DECIMA SEXTA': 'XVI', 'D√âCIMA SEXTA': 'XVI', '√ëUBLE': 'XVI'
    }
    
    # Buscar variantes exactas primero
    if region_str in variantes:
        return variantes[region_str]
    
    # Buscar si contiene "REGION" o "REGI√ìN" seguido de n√∫mero
    if 'REGION' in region_str or 'REGI√ìN' in region_str:
        # Extraer n√∫mero o romano
        numeros = re.findall(r'\d+', region_str)
        if numeros:
            num = numeros[0]
            if num in numero_a_romano:
                return numero_a_romano[num]
        
        # Buscar n√∫meros romanos
        for romano in ['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X', 'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI']:
            if romano in region_str:
                return romano
        
        # Buscar RM
        if 'METROPOLITANA' in region_str or 'SANTIAGO' in region_str:
            return 'RM'
    
    # Si es solo un n√∫mero, convertir a romano
    if region_str.isdigit():
        if region_str in numero_a_romano:
            return numero_a_romano[region_str]
    
    # Si ya es un romano v√°lido, devolverlo
    if region_str in ['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X', 'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI', 'RM']:
        return region_str
    
    # Si contiene valores inv√°lidos
    if region_str in ['NAN', 'NONE', 'SIN REGI√ìN', 'SIN REGION', 'SIN REGI√≥N', '']:
        return 'Sin Regi√≥n'
    
    # Si no se puede normalizar, devolver el original (puede ayudar a debug)
    return region_str

try:
    from src.models.prediction import FireRiskPredictor
    from src.optimization.resource_allocation import ResourceAllocationOptimizer
except ImportError as e:
    st.error(f"Error al importar m√≥dulos: {e}")
    st.stop()

# Configuraci√≥n de la p√°gina
# NOTA: Esta configuraci√≥n puede ya haberse hecho en streamlit_app.py
# Si ya est√° configurado, esta llamada ser√° ignorada sin causar error
try:
    st.set_page_config(
        page_title="Sistema de Incendios Forestales - CONAF Chile",
        page_icon="üî•",
        layout="wide",
        initial_sidebar_state="expanded"
    )
except Exception:
    # Si ya est√° configurado (desde streamlit_app.py), ignorar
    pass

# NOTA: El t√≠tulo ya se muestra en streamlit_app.py para evitar duplicaci√≥n
# Solo mostramos el mensaje importante y separador
st.info("üí° **IMPORTANTE:** Usa los filtros en la barra lateral (‚Üê) para seleccionar a√±os, regiones y comunas espec√≠ficas. Los datos se actualizar√°n autom√°ticamente.")

st.markdown("---")

# Cargar datos reales una vez
@st.cache_data
def load_conaf_data():
    """Carga datos reales de CONAF"""
    file_path = Path("data/processed/conaf_datos_reales_completo.csv")
    
    if file_path.exists():
        try:
            df = pd.read_csv(file_path)
            # Convertir anio a int
            df['anio'] = pd.to_numeric(df['anio'], errors='coerce')
            df = df[df['anio'].notna()]
            # Corregir a√±os (algunos est√°n como 84 en lugar de 1984)
            df.loc[df['anio'] < 1900, 'anio'] = df.loc[df['anio'] < 1900, 'anio'] + 1900
            df['anio'] = df['anio'].astype(int)
            # Limpiar comunas
            df['comuna'] = df['comuna'].astype(str).str.strip().str.title()
            
            # Normalizar regiones usando funci√≥n robusta
            df['region'] = df['region'].apply(normalizar_region)
            
            # Completar regiones faltantes usando mapeo de comunas
            # Identificar filas sin regi√≥n o con 'Sin Regi√≥n'
            sin_region_mask = (df['region'].isna()) | (df['region'] == 'Sin Regi√≥n') | (df['region'] == '')
            
            if sin_region_mask.any():
                # Para cada comuna sin regi√≥n, buscar en el mapeo
                for idx in df[sin_region_mask].index:
                    comuna = df.loc[idx, 'comuna']
                    region_encontrada = obtener_region_por_comuna(comuna)
                    if region_encontrada:
                        # Normalizar la regi√≥n encontrada
                        df.loc[idx, 'region'] = normalizar_region(region_encontrada)
            
            # Validar y limpiar datos num√©ricos
            # Asegurar que num_incendios y area_quemada_ha sean num√©ricos
            if 'num_incendios' in df.columns:
                df['num_incendios'] = pd.to_numeric(df['num_incendios'], errors='coerce').fillna(0).astype(int)
            
            if 'area_quemada_ha' in df.columns:
                df['area_quemada_ha'] = pd.to_numeric(df['area_quemada_ha'], errors='coerce').fillna(0)
                # Asegurar que no haya valores negativos
                df['area_quemada_ha'] = df['area_quemada_ha'].clip(lower=0)
            
            # Validar consistencia: si hay incendios pero √°rea es 0, puede ser v√°lido (incendios muy peque√±os)
            # pero tambi√©n puede ser un error. Ajustar casos donde num_incendios > 0 y area_quemada_ha == 0
            # Asignar un m√≠nimo razonable (0.01 ha = 100 m¬≤) para incendios muy peque√±os
            inconsistencias = (df['num_incendios'] > 0) & (df['area_quemada_ha'] == 0)
            if inconsistencias.any():
                # Para incendios registrados pero sin √°rea, asignar un m√≠nimo razonable
                # Esto representa incendios muy peque√±os (< 1 ha) que fueron controlados r√°pidamente
                df.loc[inconsistencias, 'area_quemada_ha'] = 0.01  # 0.01 ha = 100 m¬≤ (m√≠nimo razonable)
            
            return df
        except Exception as e:
            st.error(f"Error al cargar datos: {e}")
            return None
    
    # Si no existe, mostrar mensaje √∫til y sugerir alternativas
    st.error("""
    ‚ùå **Dataset procesado no encontrado**
    
    El archivo `data/processed/conaf_datos_reales_completo.csv` no est√° disponible.
    """)
    
    with st.expander("üîß Soluciones", expanded=True):
        st.markdown("""
        **Opci√≥n 1: Incluir dataset en el repositorio (Recomendado)**
        
        1. Edita `.gitignore` y agrega esta l√≠nea para permitir el dataset:
           ```
           !data/processed/conaf_datos_reales_completo.csv
           ```
        
        2. Agrega el archivo al repositorio:
           ```bash
           git add data/processed/conaf_datos_reales_completo.csv
           git commit -m "Add processed CONAF dataset"
           git push
           ```
        
        **Opci√≥n 2: Procesar datos autom√°ticamente**
        
        El sistema puede intentar procesar datos autom√°ticamente si los archivos raw
        de CONAF est√°n disponibles en `data/raw/`.
        """)
        
        if st.button("üîÑ Intentar Procesar Datos Autom√°ticamente", type="secondary"):
            with st.spinner("Buscando archivos CONAF raw para procesar..."):
                try:
                    from src.data.conaf_smart_processor import SmartCONAFProcessor
                    processor = SmartCONAFProcessor()
                    df = processor.process_all_files()
                    if len(df) > 0:
                        st.success(f"‚úÖ Datos procesados autom√°ticamente: {len(df):,} registros")
                        # Guardar para uso futuro
                        output_path = Path("data/processed/conaf_datos_reales_completo.csv")
                        output_path.parent.mkdir(parents=True, exist_ok=True)
                        df.to_csv(output_path, index=False)
                        st.info("üíæ Dataset guardado en `data/processed/conaf_datos_reales_completo.csv`")
                        st.rerun()
                    else:
                        st.error("‚ùå No se encontraron archivos CONAF para procesar")
                        st.info("üí° Por favor coloca los archivos Excel/XLS de CONAF en `data/raw/`")
                except FileNotFoundError as e:
                    st.error(f"‚ùå Archivos raw no encontrados: {e}")
                    st.info("üí° Necesitas los archivos Excel/XLS de CONAF en `data/raw/`")
                except Exception as e:
                    st.error(f"‚ùå Error al procesar: {e}")
                    import traceback
                    with st.expander("Detalles del error"):
                        st.code(traceback.format_exc())
    
    return None

# Inicializar datos
try:
    if 'conaf_data' not in st.session_state:
        with st.spinner("Cargando datos de CONAF..."):
            st.session_state.conaf_data = load_conaf_data()

    if st.session_state.conaf_data is None or len(st.session_state.conaf_data) == 0:
        # Mostrar mensaje de error claramente ANTES de detenerse
        st.error("‚ùå **No se encontraron datos de CONAF**")
        st.warning("""
        **El dataset procesado no est√° disponible.**
        
        Por favor verifica que el archivo `data/processed/conaf_datos_reales_completo.csv` 
        est√© en el repositorio de GitHub.
        """)
        
        st.info("""
        **Para solucionar:**
        1. Verifica que el archivo existe en GitHub: `data/processed/conaf_datos_reales_completo.csv`
        2. Si no existe, agr√©galo al repositorio:
           ```bash
           git add data/processed/conaf_datos_reales_completo.csv
           git commit -m "Add dataset"
           git push
           ```
        3. Espera 1-2 minutos para que Streamlit Cloud se actualice
        """)
        
        # Mostrar informaci√≥n de debug
        with st.expander("üîç Informaci√≥n de Debug", expanded=True):
            data_path = Path("data/processed/conaf_datos_reales_completo.csv")
            st.write(f"**Ruta esperada:** `{data_path}`")
            st.write(f"**Ruta absoluta:** `{data_path.absolute()}`")
            st.write(f"**Existe:** `{data_path.exists()}`")
            
            if data_path.exists():
                st.success(f"‚úÖ Archivo encontrado: {data_path.stat().st_size:,} bytes")
            else:
                st.error("‚ùå Archivo NO encontrado")
            
            # Listar archivos en data/processed
            processed_dir = Path("data/processed")
            st.write(f"\n**Directorio data/processed existe:** `{processed_dir.exists()}`")
            if processed_dir.exists():
                st.write("**Archivos en data/processed:**")
                files = list(processed_dir.iterdir())
                if files:
                    for f in files:
                        st.write(f"  - `{f.name}` ({f.stat().st_size:,} bytes)")
                else:
                    st.write("  (vac√≠o)")
            else:
                st.write("  (directorio no existe)")
        
        # Mostrar que la app est√° funcionando pero sin datos
        st.sidebar.warning("‚ö†Ô∏è Dashboard sin datos - Ver informaci√≥n arriba")
        
        # NO usar st.stop() aqu√≠ - dejar que se muestre el error
        # En su lugar, crear un DataFrame vac√≠o para evitar errores posteriores
        st.session_state.conaf_data = pd.DataFrame(columns=['comuna', 'region', 'anio', 'num_incendios', 'area_quemada_ha'])
        
except Exception as e:
    st.error(f"‚ùå **Error al inicializar datos**")
    st.exception(e)
    import traceback
    with st.expander("üîç Detalles t√©cnicos del error", expanded=True):
        st.code(traceback.format_exc())
    
    # Crear DataFrame vac√≠o para evitar m√°s errores
    st.session_state.conaf_data = pd.DataFrame(columns=['comuna', 'region', 'anio', 'num_incendios', 'area_quemada_ha'])
    st.sidebar.error(f"Error: {str(e)[:50]}...")

# Obtener datos base - verificar que existe
if 'conaf_data' not in st.session_state or st.session_state.conaf_data is None:
    # Si no hay datos, crear DataFrame vac√≠o
    st.session_state.conaf_data = pd.DataFrame(columns=['comuna', 'region', 'anio', 'num_incendios', 'area_quemada_ha'])

df_base = st.session_state.conaf_data.copy()

# Si no hay datos, mostrar advertencia pero continuar
if len(df_base) == 0:
    st.warning("‚ö†Ô∏è **No hay datos disponibles.** Por favor verifica la informaci√≥n de debug arriba.")

# Sidebar - Filtros
st.sidebar.header("‚öôÔ∏è Filtros y Configuraci√≥n")

# Filtros en sidebar
st.sidebar.subheader("üìÖ Filtro de A√±os")
# Manejar caso cuando no hay datos o DataFrame est√° vac√≠o
if len(df_base) > 0 and 'anio' in df_base.columns:
    anos_disponibles = sorted(df_base['anio'].dropna().unique())
    ano_min = int(anos_disponibles[0]) if len(anos_disponibles) > 0 else 1985
    ano_max = int(anos_disponibles[-1]) if len(anos_disponibles) > 0 else 2023
else:
    # Valores por defecto si no hay datos
    anos_disponibles = []
    ano_min = 1985
    ano_max = 2023

ano_inicio = st.sidebar.number_input(
    "A√±o Inicio",
    min_value=ano_min,
    max_value=ano_max,
    value=max(2015, ano_min),
    step=1,
    key="ano_inicio"
)

ano_fin = st.sidebar.number_input(
    "A√±o Fin",
    min_value=ano_min,
    max_value=ano_max,
    value=ano_max,
    step=1,
    key="ano_fin"
)

if ano_inicio > ano_fin:
    st.sidebar.warning("‚ö†Ô∏è El a√±o inicio debe ser menor o igual al a√±o fin")
    ano_fin = ano_inicio

# Filtro de regiones
st.sidebar.subheader("üó∫Ô∏è Filtro de Regiones")
# Manejar caso cuando no hay datos
if len(df_base) > 0 and 'region' in df_base.columns:
    # Obtener todas las regiones √∫nicas, excluyendo 'Sin Regi√≥n' y valores inv√°lidos
    regiones_unicas = df_base['region'].dropna().unique()
    regiones_unicas = [
        r for r in regiones_unicas 
        if pd.notna(r) 
        and str(r).strip() != '' 
        and str(r) != 'Sin Regi√≥n'
    ]
    
    # Funci√≥n para ordenar regiones de forma inteligente
    def ordenar_region(region):
        region_str = str(region)
        # Mapeo de n√∫meros romanos
        romanos = {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5, 'VI': 6, 
                  'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10, 'XI': 11, 'XII': 12,
                  'XIII': 13, 'XIV': 14, 'XV': 15, 'XVI': 16, 'RM': 17}
        
        if region_str in romanos:
            return (0, romanos[region_str])
        
        # Si no es una regi√≥n conocida, poner al final
        return (1, region_str)
    
    # Ordenar regiones
    regiones_disponibles = sorted(regiones_unicas, key=ordenar_region)
else:
    regiones_disponibles = []

# Permitir selecci√≥n m√∫ltiple de regiones
regiones_seleccionadas = st.sidebar.multiselect(
    "Seleccionar Regi√≥n(es)",
    regiones_disponibles,
    default=[],
    key="region_select"
)

# Filtro de comunas (depende de regi√≥n)
st.sidebar.subheader("üèòÔ∏è Filtro de Comunas")
# Manejar caso cuando no hay datos
if len(df_base) > 0 and 'comuna' in df_base.columns:
    # Si hay regiones seleccionadas, filtrar comunas por esas regiones
    if len(regiones_seleccionadas) > 0:
        # Normalizar las regiones seleccionadas para comparar con el dataframe
        regiones_seleccionadas_normalizadas = [normalizar_region(r) for r in regiones_seleccionadas]
        
        # Filtrar comunas que pertenecen a las regiones seleccionadas
        df_filtrado_region = df_base[df_base['region'].isin(regiones_seleccionadas_normalizadas)]
        
        # Obtener comunas √∫nicas del dataframe filtrado
        comunas_unicas = df_filtrado_region['comuna'].dropna().unique()
        comunas_disponibles = sorted([
            c for c in comunas_unicas 
            if pd.notna(c) 
            and str(c).strip() != ''
            and str(c).strip().upper() not in ['NAN', 'NONE', 'CORPORACION', 'NACIONAL', 'FORESTAL']
        ])
    else:
        # Si no hay regiones seleccionadas, mostrar todas las comunas
        comunas_unicas = df_base['comuna'].dropna().unique()
        comunas_disponibles = sorted([
            c for c in comunas_unicas 
            if pd.notna(c) 
            and str(c).strip() != ''
            and str(c).strip().upper() not in ['NAN', 'NONE', 'CORPORACION', 'NACIONAL', 'FORESTAL']
        ])
else:
    comunas_disponibles = []

# Permitir selecci√≥n m√∫ltiple de comunas
comunas_seleccionadas = st.sidebar.multiselect(
    "Seleccionar Comuna(s)",
    comunas_disponibles,
    default=[],
    key="comuna_select"
)

# Aplicar filtros
try:
    df_filtrado = df_base[
        (df_base['anio'] >= ano_inicio) &
        (df_base['anio'] <= ano_fin)
    ].copy()
    
    # Filtrar por regiones seleccionadas (si hay alguna seleccionada)
    if len(regiones_seleccionadas) > 0:
        # Normalizar las regiones seleccionadas para comparar con el dataframe
        regiones_seleccionadas_normalizadas = [normalizar_region(r) for r in regiones_seleccionadas]
        df_filtrado = df_filtrado[df_filtrado['region'].isin(regiones_seleccionadas_normalizadas)]
    
    # Filtrar por comunas seleccionadas (si hay alguna seleccionada)
    if len(comunas_seleccionadas) > 0:
        df_filtrado = df_filtrado[df_filtrado['comuna'].isin(comunas_seleccionadas)]
except Exception as e:
    st.sidebar.error(f"Error al aplicar filtros: {e}")
    df_filtrado = df_base.copy()

# Mostrar info de filtros
st.sidebar.markdown("---")
region_info = ", ".join(regiones_seleccionadas[:2]) if len(regiones_seleccionadas) > 0 else "Todas"
if len(regiones_seleccionadas) > 2:
    region_info += f" (+{len(regiones_seleccionadas)-2} m√°s)"
comuna_info = ", ".join(comunas_seleccionadas[:2]) if len(comunas_seleccionadas) > 0 else "Todas"
if len(comunas_seleccionadas) > 2:
    comuna_info += f" (+{len(comunas_seleccionadas)-2} m√°s)"

st.sidebar.info(f"""
**Datos Filtrados:**
- Registros: {len(df_filtrado):,}
- A√±os: {ano_inicio}-{ano_fin}
- Regi√≥n(es): {region_info}
- Comuna(s): {comuna_info}
""")

# Guardar datos filtrados en sesi√≥n
st.session_state.datos_filtrados = df_filtrado

# Inicializar sesi√≥n para otras variables
if 'predictor' not in st.session_state:
    st.session_state.predictor = None
if 'risk_map' not in st.session_state:
    st.session_state.risk_map = None
if 'optimizer' not in st.session_state:
    st.session_state.optimizer = ResourceAllocationOptimizer()

# Tabs
tab1, tab2, tab3, tab4 = st.tabs([
    "üìä Datos y An√°lisis",
    "ü§ñ Predicci√≥n de Riesgo",
    "üéØ Optimizaci√≥n de Recursos",
    "üìà Reportes y Estad√≠sticas"
])

# ===== TAB 1: Datos y An√°lisis =====
with tab1:
    st.header("üìä Visualizaci√≥n de Datos CONAF")
    
    if len(df_filtrado) == 0:
        st.warning("‚ö†Ô∏è No hay datos para los filtros seleccionados. Por favor ajusta los filtros en la barra lateral.")
    else:
        try:
            # Informaci√≥n sobre calidad de datos
            if 'num_incendios' in df_filtrado.columns and 'area_quemada_ha' in df_filtrado.columns:
                # Contar casos con incendios pero √°rea muy peque√±a o cero
                incendios_pequenos = ((df_filtrado['num_incendios'] > 0) & (df_filtrado['area_quemada_ha'] < 0.1)).sum()
                if incendios_pequenos > 0:
                    with st.expander("‚ÑπÔ∏è Nota sobre calidad de datos", expanded=False):
                        st.info(f"""
                        **Incendios con √°rea muy peque√±a (< 0.1 ha):** {incendios_pequenos:,} registros
                        
                        Estos casos representan:
                        - ‚úÖ **Incendios muy peque√±os** controlados r√°pidamente (< 1,000 m¬≤)
                        - ‚úÖ **Incendios que no alcanzaron 1 hect√°rea** (redondeados a 0.01 ha)
                        - ‚ö†Ô∏è **Posibles errores en los datos originales** (incendios registrados sin √°rea medida)
                        
                        Para mantener la consistencia, se ha asignado un m√≠nimo de 0.01 ha (100 m¬≤) a estos casos.
                        """)
            
            # M√©tricas principales
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_incendios = df_filtrado['num_incendios'].sum()
                st.metric("Total Incendios", f"{total_incendios:,.0f}")
            
            with col2:
                total_area = df_filtrado['area_quemada_ha'].sum()
                st.metric("√Årea Quemada Total", f"{total_area:,.2f} ha")
            
            with col3:
                comunas_unicas = df_filtrado['comuna'].nunique()
                st.metric("Comunas Afectadas", comunas_unicas)
            
            with col4:
                anos_unicos = df_filtrado['anio'].nunique()
                st.metric("A√±os Analizados", anos_unicos)
            
            st.markdown("---")
            
            # Gr√°ficos
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Incendios por A√±o")
                try:
                    incendios_anuales = df_filtrado.groupby('anio')['num_incendios'].sum().reset_index()
                    fig1 = px.bar(
                        incendios_anuales, 
                        x='anio', 
                        y='num_incendios',
                        title=f'Incendios por A√±o ({ano_inicio}-{ano_fin})',
                        labels={'num_incendios': 'N√∫mero de Incendios', 'anio': 'A√±o'},
                        color='num_incendios',
                        color_continuous_scale='Reds'
                    )
                    st.plotly_chart(fig1, width='stretch')
                except Exception as e:
                    st.error(f"Error al generar gr√°fico: {e}")
            
            with col2:
                st.subheader("√Årea Quemada por A√±o")
                try:
                    area_anual = df_filtrado.groupby('anio')['area_quemada_ha'].sum().reset_index()
                    fig2 = px.line(
                        area_anual,
                        x='anio',
                        y='area_quemada_ha',
                        title=f'√Årea Quemada por A√±o ({ano_inicio}-{ano_fin})',
                        labels={'area_quemada_ha': '√Årea (ha)', 'anio': 'A√±o'},
                        markers=True
                    )
                    st.plotly_chart(fig2, width='stretch')
                except Exception as e:
                    st.error(f"Error al generar gr√°fico: {e}")
            
            # Top comunas con m√°s incendios
            st.subheader("üèòÔ∏è Top 15 Comunas con M√°s Incendios (Per√≠odo Seleccionado)")
            try:
                top_comunas = (
                    df_filtrado.groupby('comuna')['num_incendios']
                    .sum()
                    .sort_values(ascending=False)
                    .head(15)
                    .reset_index()
                )
                top_comunas.columns = ['Comuna', 'Total Incendios']
                st.dataframe(top_comunas, width='stretch', height=400)
                
                # Gr√°fico de top comunas
                fig_top = px.bar(
                    top_comunas,
                    x='Total Incendios',
                    y='Comuna',
                    orientation='h',
                    title='Top 15 Comunas con M√°s Incendios',
                    labels={'Total Incendios': 'N√∫mero de Incendios'},
                    color='Total Incendios',
                    color_continuous_scale='Oranges'
                )
                fig_top.update_layout(yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_top, width='stretch')
            except Exception as e:
                st.error(f"Error al generar top comunas: {e}")
            
            # Tabla de datos
            with st.expander("üìã Ver Datos Detallados"):
                try:
                    st.dataframe(
                        df_filtrado[['comuna', 'region', 'anio', 'num_incendios', 'area_quemada_ha', 'temporada']].sort_values('num_incendios', ascending=False),
                        width='stretch',
                        height=400
                    )
                except Exception as e:
                    st.error(f"Error al mostrar datos: {e}")
        
        except Exception as e:
            st.error(f"Error en visualizaci√≥n: {e}")
            import traceback
            st.code(traceback.format_exc())

# ===== TAB 2: Predicci√≥n de Riesgo =====
with tab2:
    st.header("ü§ñ Modelo de Predicci√≥n de Riesgo")
    
    if len(df_filtrado) == 0:
        st.warning("‚ö†Ô∏è Por favor selecciona datos v√°lidos usando los filtros en la barra lateral.")
    else:
        st.info(f"üí° Analizando {len(df_filtrado):,} registros de {df_filtrado['comuna'].nunique()} comunas entre {ano_inicio} y {ano_fin}")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("Configuraci√≥n del Modelo")
            
            # Explicaci√≥n de tipos de modelo
            with st.expander("‚ÑπÔ∏è ¬øQu√© tipo de modelo elegir?", expanded=False):
                st.markdown("""
                **XGBoost** (Recomendado):
                - ‚úÖ Mejor rendimiento general para datos tabulares
                - ‚úÖ Maneja bien relaciones no lineales
                - ‚úÖ Buen balance entre velocidad y precisi√≥n
                - ‚úÖ Ideal para: Predicci√≥n de riesgo de incendios
                
                **LightGBM**:
                - ‚úÖ Muy r√°pido en entrenamiento
                - ‚úÖ Eficiente con datasets grandes
                - ‚úÖ Buen rendimiento, similar a XGBoost
                - ‚úÖ Ideal para: An√°lisis r√°pidos o datasets muy grandes
                
                **Random Forest**:
                - ‚úÖ M√°s interpretable
                - ‚úÖ Menos propenso a overfitting
                - ‚úÖ M√°s lento que XGBoost/LightGBM
                - ‚úÖ Ideal para: Cuando necesitas entender mejor las decisiones del modelo
                """)
            
            model_type = st.selectbox(
                "Tipo de Modelo",
                ["xgboost", "lightgbm", "random_forest"],
                index=0,
                help="Selecciona el algoritmo de Machine Learning a usar"
            )
            
            # Explicaci√≥n de tipos de tarea
            with st.expander("‚ÑπÔ∏è ¬øQu√© tipo de tarea elegir?", expanded=False):
                st.markdown("""
                **Classification (Clasificaci√≥n)** - Recomendado para la mayor√≠a de casos:
                - üéØ **Objetivo**: Predecir si HABR√Å o NO HABR√Å incendio (S√≠/No)
                - üìä **Output**: Probabilidad de riesgo (0% a 100%)
                - ‚úÖ **Ideal para**: 
                    - Alertas tempranas ("¬øHay riesgo de incendio hoy?")
                    - Asignaci√≥n preventiva de recursos
                    - Identificar zonas de alto riesgo
                - üìà **M√©tricas**: Accuracy, Precision, Recall, F1-Score, ROC-AUC
                
                **Regression (Regresi√≥n)**:
                - üéØ **Objetivo**: Predecir CU√ÅNTOS incendios habr√° (n√∫mero exacto)
                - üìä **Output**: N√∫mero estimado de incendios
                - ‚úÖ **Ideal para**:
                    - Planificaci√≥n de recursos (¬øcu√°ntas brigadas necesito?)
                    - Estimaci√≥n de da√±o esperado
                    - Presupuestos y log√≠stica
                - üìà **M√©tricas**: RMSE, MAE, R¬≤
                
                **üí° Recomendaci√≥n**: Usa **Classification** para la mayor√≠a de casos de uso operacional.
                """)
            
            task_type = st.selectbox(
                "Tipo de Tarea",
                ["classification", "regression"],
                index=0,
                help="Classification: ¬øHabr√° incendio? | Regression: ¬øCu√°ntos incendios?"
            )
        
        with col2:
            st.subheader("Entrenamiento")
            
            # Informaci√≥n importante sobre c√≥mo funcionan los modelos
            st.info("""
            **üìù ¬øC√≥mo funcionan los modelos?**
            
            - **Se entrenan sobre la marcha**: Al hacer clic en "Entrenar Modelo", se entrena un nuevo modelo con los datos filtrados.
            - **Se guardan en la sesi√≥n**: Una vez entrenado, el modelo permanece disponible durante tu sesi√≥n de navegador.
            - **No hay modelos pre-entrenados**: Cada usuario debe entrenar su propio modelo, lo que permite ajustarlo a datos espec√≠ficos.
            - **Se pierden al cerrar**: Si cierras el navegador, necesitar√°s entrenar el modelo nuevamente.
            """)
            
            # Informaci√≥n sobre el entrenamiento
            st.info(f"""
            **Datos para entrenar:**
            - {len(df_filtrado):,} registros
            - {df_filtrado['comuna'].nunique()} comunas
            - Per√≠odo: {ano_inicio}-{ano_fin}
            
            El modelo aprender√° patrones hist√≥ricos de estos datos.
            """)
            
            if st.button("üöÄ Entrenar Modelo", type="primary", use_container_width=True):
                with st.spinner("Entrenando modelo con datos reales..."):
                    try:
                        # Preparar datos para ML
                        # IMPORTANTE: Crear panel completo incluyendo comunas sin incendios
                        # para tener ambas clases (0 = sin incendio, 1 = con incendio)
                        
                        # Obtener todas las combinaciones posibles de comuna-a√±o
                        todas_comunas = df_filtrado['comuna'].unique()
                        todos_anios = sorted(df_filtrado['anio'].unique())
                        
                        # Crear panel completo con todas las combinaciones
                        from itertools import product
                        panel_completo = pd.DataFrame(
                            list(product(todas_comunas, todos_anios)),
                            columns=['comuna', 'anio']
                        )
                        
                        # Agregar datos reales
                        panel_agregado = df_filtrado.groupby(['comuna', 'anio']).agg({
                            'num_incendios': 'sum',
                            'area_quemada_ha': 'sum'
                        }).reset_index()
                        
                        # Merge: los que no tienen datos tendr√°n NaN en num_incendios
                        panel_df = panel_completo.merge(
                            panel_agregado,
                            on=['comuna', 'anio'],
                            how='left'
                        )
                        
                        # Llenar NaN con 0 (comunas sin incendios en ese a√±o)
                        panel_df['num_incendios'] = panel_df['num_incendios'].fillna(0)
                        panel_df['area_quemada_ha'] = panel_df['area_quemada_ha'].fillna(0)
                        
                        # Preparar datos para ML
                        # Agregar features temporales m√°s robustas
                        panel_df['mes'] = 1  # Feature temporal b√°sica
                        panel_df['dia_anio'] = panel_df['anio'] * 365  # D√≠a del a√±o aproximado
                        
                        # Feature de a√±o (normalizado para ayudar al modelo)
                        anos_unicos = sorted(panel_df['anio'].unique())
                        ano_min = min(anos_unicos)
                        ano_max = max(anos_unicos)
                        panel_df['anio_normalizado'] = (panel_df['anio'] - ano_min) / (ano_max - ano_min + 1e-10)
                        
                        # Features c√≠clicas temporales (para capturar patrones estacionales)
                        panel_df['mes_sin'] = np.sin(2 * np.pi * panel_df['mes'] / 12)
                        panel_df['mes_cos'] = np.cos(2 * np.pi * panel_df['mes'] / 12)
                        
                        # Agregar features hist√≥ricas b√°sicas por comuna (promedios hist√≥ricos)
                        historico_comuna = df_filtrado.groupby('comuna').agg({
                            'num_incendios': ['sum', 'mean', 'max', 'std'],
                            'area_quemada_ha': ['sum', 'mean']
                        }).reset_index()
                        historico_comuna.columns = ['comuna', 'incendios_total_hist', 'incendios_promedio_hist', 
                                                    'incendios_max_hist', 'incendios_std_hist', 
                                                    'area_total_hist', 'area_promedio_hist']
                        panel_df = panel_df.merge(historico_comuna, on='comuna', how='left')
                        
                        # Agregar features hist√≥ricas temporales (incendios en a√±os anteriores)
                        # Para cada comuna-a√±o, calcular incendios en a√±os anteriores
                        panel_df = panel_df.sort_values(['comuna', 'anio'])
                        panel_df['incendios_anio_anterior'] = panel_df.groupby('comuna')['num_incendios'].shift(1).fillna(0)
                        panel_df['incendios_2_anios_antes'] = panel_df.groupby('comuna')['num_incendios'].shift(2).fillna(0)
                        panel_df['area_anio_anterior'] = panel_df.groupby('comuna')['area_quemada_ha'].shift(1).fillna(0)
                        
                        # Promedio m√≥vil de √∫ltimos 3 a√±os
                        panel_df['incendios_promedio_3_anios'] = (
                            panel_df.groupby('comuna')['num_incendios']
                            .transform(lambda x: x.rolling(window=3, min_periods=1).mean().shift(1))
                            .fillna(0)  # Si no hay datos anteriores, usar 0
                        )
                        
                        # Llenar NaN en features hist√≥ricas con 0
                        features_historicas = ['incendios_total_hist', 'incendios_promedio_hist', 
                                              'incendios_max_hist', 'incendios_std_hist', 
                                              'area_total_hist', 'area_promedio_hist']
                        for feat in features_historicas:
                            if feat in panel_df.columns:
                                panel_df[feat] = panel_df[feat].fillna(0)
                        
                        # Llenar NaN en features temporales con valores razonables
                        panel_df['incendios_std_hist'] = panel_df['incendios_std_hist'].fillna(0)
                        panel_df['incendios_promedio_3_anios'] = panel_df['incendios_promedio_3_anios'].fillna(0)
                        
                        # Crear variable objetivo - usar el nombre que espera prepare_features
                        if task_type == 'classification':
                            # Para clasificaci√≥n: 1 = hubo incendio, 0 = no hubo
                            panel_df['incendio_ocurrencia'] = (panel_df['num_incendios'] > 0).astype(int)
                            target_col = 'incendio_ocurrencia'
                        else:
                            # Para regresi√≥n: queremos predecir el n√∫mero de incendios
                            # Pero prepare_features espera 'incendio_ocurrencia', as√≠ que usamos num_incendios como target
                            panel_df['incendio_ocurrencia'] = panel_df['num_incendios'].copy()
                            target_col = 'incendio_ocurrencia'
                        
                        # Crear predictor
                        predictor = FireRiskPredictor(model_type=model_type, task=task_type)
                        
                        # Preparar features - pasar el nombre de la columna objetivo
                        X, y = predictor.prepare_features(panel_df, target_col=target_col)
                        
                        # Diagn√≥stico antes de entrenar
                        if task_type == 'regression':
                            with st.expander("üîç Diagn√≥stico de Datos para Regresi√≥n", expanded=True):
                                st.markdown(f"""
                                **Distribuci√≥n del target (num_incendios):**
                                - Total de muestras: {len(y):,}
                                - M√≠nimo: {y.min():.0f}
                                - M√°ximo: {y.max():.0f}
                                - Media: {y.mean():.3f}
                                - Mediana: {y.median():.3f}
                                - Desviaci√≥n est√°ndar: {y.std():.3f}
                                - Muestras con 0 incendios: {(y == 0).sum():,} ({(y == 0).mean()*100:.1f}%)
                                - Muestras con >0 incendios: {(y > 0).sum():,} ({(y > 0).mean()*100:.1f}%)
                                
                                **Features disponibles:**
                                - N√∫mero de features: {len(X.columns)}
                                - Features: {', '.join(X.columns[:10].tolist())}{'...' if len(X.columns) > 10 else ''}
                                
                                **üí° Nota:** Un R¬≤ negativo indica que el modelo predice peor que simplemente usar la media del target.
                                Esto puede ocurrir si:
                                - Las features no son suficientemente informativas
                                - Hay muchos valores cero (datos esparcidos)
                                - El modelo necesita m√°s datos o features m√°s relevantes
                                """)
                        
                        # Entrenar
                        metrics = predictor.train(X, y, validation_size=0.2, temporal_split=True)
                        
                        # Guardar en sesi√≥n
                        st.session_state.predictor = predictor
                        st.session_state.panel_data = panel_df
                        st.session_state.task_type = task_type  # Guardar tipo de tarea para predicci√≥n
                        st.session_state.model_type = model_type  # Guardar tipo de modelo para validaci√≥n
                        # Limpiar mapa de riesgo anterior cuando se entrena un nuevo modelo
                        st.session_state.risk_map = None
                        
                        st.success(f"‚úÖ Modelo {model_type.upper()} ({task_type}) entrenado exitosamente con datos reales")
                        
                        # Mostrar m√©tricas seg√∫n el tipo de tarea
                        st.subheader("üìä M√©tricas del Modelo")
                        
                        if task_type == 'classification':
                            # M√©tricas de clasificaci√≥n
                            col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                            
                            with col_m1:
                                accuracy_val = float(metrics.get('accuracy', 0))
                                st.markdown(f"**Accuracy:**")
                                st.markdown(f"### {accuracy_val:.3f}")
                                st.caption("Porcentaje de predicciones correctas")
                            
                            with col_m2:
                                f1_val = float(metrics.get('f1', 0))
                                st.markdown(f"**F1-Score:**")
                                st.markdown(f"### {f1_val:.3f}")
                                st.caption("Balance entre precisi√≥n y recall")
                            
                            with col_m3:
                                precision_val = float(metrics.get('precision', 0))
                                st.markdown(f"**Precision:**")
                                st.markdown(f"### {precision_val:.3f}")
                                st.caption("Verdaderos positivos / (Verdaderos + Falsos positivos)")
                            
                            with col_m4:
                                recall_val = float(metrics.get('recall', 0))
                                st.markdown(f"**Recall:**")
                                st.markdown(f"### {recall_val:.3f}")
                                st.caption("Verdaderos positivos / (Verdaderos positivos + Falsos negativos)")
                            
                            # ROC-AUC en una fila separada si existe
                            if metrics.get('roc_auc') is not None:
                                roc_auc_val = float(metrics.get('roc_auc', 0))
                                col_roc1, col_roc2 = st.columns([1, 3])
                                with col_roc1:
                                    st.markdown(f"**ROC-AUC:**")
                                    st.markdown(f"### {roc_auc_val:.3f}")
                                    st.caption("√Årea bajo la curva ROC (0.5 = aleatorio, 1.0 = perfecto)")
                        
                        else:  # regression
                            # M√©tricas de regresi√≥n
                            col_m1, col_m2, col_m3 = st.columns(3)
                            
                            with col_m1:
                                rmse_val = float(metrics.get('rmse', 0))
                                st.markdown(f"**RMSE:**")
                                st.markdown(f"### {rmse_val:.3f}")
                                st.caption("Ra√≠z del error cuadr√°tico medio (menor es mejor)")
                            
                            with col_m2:
                                mae_val = float(metrics.get('mae', 0))
                                st.markdown(f"**MAE:**")
                                st.markdown(f"### {mae_val:.3f}")
                                st.caption("Error absoluto medio (menor es mejor)")
                            
                            with col_m3:
                                r2_val = float(metrics.get('r2', 0))
                                st.markdown(f"**R¬≤:**")
                                
                                # Mostrar R¬≤ con color seg√∫n su valor
                                if r2_val < 0:
                                    st.markdown(f"### ‚ö†Ô∏è {r2_val:.3f}")
                                    st.caption("‚ö†Ô∏è **NEGATIVO**: El modelo es peor que predecir la media")
                                elif r2_val < 0.3:
                                    st.markdown(f"### ‚ö†Ô∏è {r2_val:.3f}")
                                    st.caption("‚ö†Ô∏è **BAJO**: El modelo explica poca variabilidad")
                                elif r2_val < 0.7:
                                    st.markdown(f"### {r2_val:.3f}")
                                    st.caption("‚ö†Ô∏è **MODERADO**: El modelo explica variabilidad moderada")
                                else:
                                    st.markdown(f"### ‚úÖ {r2_val:.3f}")
                                    st.caption("‚úÖ **ALTO**: El modelo explica mucha variabilidad")
                            
                            # Informaci√≥n adicional sobre interpretaci√≥n
                            if r2_val < 0:
                                st.error(f"""
                                **‚ö†Ô∏è R¬≤ NEGATIVO ({r2_val:.3f}) - El modelo est√° funcionando muy mal:**
                                
                                Esto significa que el modelo predice **peor que simplemente usar la media** del target.
                                
                                **Posibles causas:**
                                1. **Features insuficientes**: Las features no capturan patrones relevantes
                                2. **Datos esparcidos**: Muchos valores en cero hacen dif√≠cil aprender patrones
                                3. **Overfitting**: El modelo memoriza el entrenamiento pero no generaliza
                                4. **Split temporal problem√°tico**: Datos de validaci√≥n muy diferentes a entrenamiento
                                5. **Modelo inadecuado**: El algoritmo puede no ser el mejor para estos datos
                                
                                **Soluciones sugeridas:**
                                - ‚úÖ Usa **classification** en lugar de regression (predice ocurrencia, no cantidad)
                                - ‚úÖ Incluye m√°s features relevantes (datos clim√°ticos, geogr√°ficos)
                                - ‚úÖ Aumenta el rango de a√±os en los filtros
                                - ‚úÖ Considera transformar el target (log, binning)
                                """)
                            else:
                                st.info(f"""
                                **Interpretaci√≥n de m√©tricas de regresi√≥n:**
                                
                                - **RMSE ({rmse_val:.3f})**: Error promedio en la misma unidad que el target. 
                                  Indica cu√°ntos incendios se predice incorrectamente en promedio.
                                  {f"‚ö†Ô∏è Alto: {rmse_val:.1f} errores en promedio" if rmse_val > 10 else "‚úÖ Razonable"}
                                
                                - **MAE ({mae_val:.3f})**: Error absoluto promedio. M√°s f√°cil de interpretar que RMSE.
                                
                                - **R¬≤ ({r2_val:.3f})**: Porcentaje de variabilidad explicada por el modelo.
                                  - R¬≤ = 1.0: Predicci√≥n perfecta
                                  - R¬≤ = 0.0: El modelo no es mejor que predecir la media
                                  - R¬≤ < 0.0: El modelo es peor que predecir la media ‚ö†Ô∏è
                                  - R¬≤ > 0.7: Buen ajuste ‚úÖ
                                """)
                        
                        # Feature importance
                        if predictor.feature_importance is not None and len(predictor.feature_importance) > 0:
                            st.subheader("üîç Importancia de Features (Top 10)")
                            top_features = predictor.feature_importance.head(10)
                            fig_importance = px.bar(
                                top_features,
                                x='importance',
                                y='feature',
                                orientation='h',
                                title='Top 10 Features M√°s Importantes',
                                color='importance',
                                color_continuous_scale='Blues'
                            )
                            fig_importance.update_layout(yaxis={'categoryorder': 'total ascending'})
                            st.plotly_chart(fig_importance, width='stretch')
                    
                    except Exception as e:
                        st.error(f"Error al entrenar modelo: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
        
        # Predicci√≥n de riesgo
        if st.session_state.predictor is not None:
            # Mostrar informaci√≥n del modelo actual
            model_type_actual = st.session_state.get('model_type', 'desconocido')
            task_type_actual = st.session_state.get('task_type', 'desconocido')
            st.success(f"‚úÖ Modelo {model_type_actual.upper()} ({task_type_actual}) entrenado y listo para hacer predicciones")
            
            # Mostrar advertencia si el modelo actual no coincide con el seleccionado
            if model_type_actual != model_type:
                st.warning(f"‚ö†Ô∏è **IMPORTANTE:** El modelo actualmente entrenado es **{model_type_actual.upper()}**, pero has seleccionado **{model_type.upper()}** en el selector. "
                          f"Las predicciones usar√°n el modelo **{model_type_actual.upper()}** que est√° actualmente entrenado. "
                          f"Para usar **{model_type.upper()}**, haz clic en 'üöÄ Entrenar Modelo' con el tipo seleccionado.")
            
            # Mostrar informaci√≥n sobre el modelo actual
            with st.expander("‚ÑπÔ∏è Informaci√≥n del Modelo Actual", expanded=False):
                st.markdown(f"""
                **Modelo actualmente entrenado:** {model_type_actual.upper()}  
                **Tipo de tarea:** {task_type_actual}  
                **Modelo seleccionado en el selector:** {model_type.upper()}  
                
                **üí° Nota:** Si quieres cambiar el modelo, selecciona el tipo de modelo que deseas y haz clic en "üöÄ Entrenar Modelo". 
                Cada modelo (XGBoost, LightGBM, Random Forest) puede dar resultados diferentes incluso con los mismos datos.
                """)
            
            st.markdown("---")
            st.subheader("üó∫Ô∏è Mapa de Riesgo")
            
            if st.button("üîÆ Generar Mapa de Riesgo", type="primary"):
                with st.spinner("Generando mapa de riesgo..."):
                    try:
                        ultimo_anio = df_filtrado['anio'].max()
                        comunas_unicas = df_filtrado['comuna'].unique()
                        
                        pred_df = pd.DataFrame({
                            'comuna': comunas_unicas,
                            'anio': ultimo_anio + 1,
                            'mes': 1,
                            'dia_anio': (ultimo_anio + 1) * 365
                        })
                        
                        historico_comuna = df_filtrado.groupby('comuna').agg({
                            'num_incendios': ['sum', 'mean', 'max'],
                            'area_quemada_ha': 'sum'
                        }).reset_index()
                        
                        historico_comuna.columns = ['comuna', 'incendios_total', 'incendios_promedio', 'incendios_max', 'area_total']
                        pred_df = pred_df.merge(historico_comuna, on='comuna', how='left')
                        
                        # Agregar columna dummy 'incendio_ocurrencia' que prepare_features espera (no se usar√° para predicci√≥n)
                        # Usamos 0 como valor dummy ya que es solo para satisfacer el formato esperado
                        pred_df['incendio_ocurrencia'] = 0
                        
                        # Obtener task_type de session_state si existe
                        task_type_pred = st.session_state.get('task_type', 'classification')
                        
                        # Validar que el modelo est√° entrenado
                        if st.session_state.predictor.model is None:
                            st.error("‚ùå Error: El modelo no est√° entrenado. Por favor entrena el modelo primero.")
                        else:
                            # Mostrar informaci√≥n del modelo que se est√° usando
                            model_type_usado = st.session_state.get('model_type', 'desconocido')
                            task_type_usado = st.session_state.get('task_type', 'desconocido')
                            
                            st.info(f"üîç Usando modelo **{model_type_usado.upper()}** ({task_type_usado}) para predicci√≥n")
                            
                            # Preparar features para predicci√≥n - pasar target_col aunque no se use
                            X_pred, _ = st.session_state.predictor.prepare_features(pred_df, target_col='incendio_ocurrencia')
                            
                            # Verificar que las features son correctas
                            if X_pred is None or len(X_pred) == 0:
                                st.error("‚ùå Error: No se pudieron preparar las features para predicci√≥n")
                            else:
                                st.info(f"üìä Prediciendo riesgo para {len(X_pred)} comunas con {len(X_pred.columns)} features")
                                
                                # Mostrar estad√≠sticas de las predicciones
                                if task_type_pred == 'classification':
                                    riesgos = st.session_state.predictor.predict(X_pred, return_proba=True)
                                else:
                                    predicciones = st.session_state.predictor.predict(X_pred)
                                    riesgos = (predicciones - predicciones.min()) / (predicciones.max() - predicciones.min() + 1e-10)
                                
                                # Mostrar estad√≠sticas detalladas de las predicciones
                                st.info(f"üìà Estad√≠sticas de predicci√≥n del modelo **{model_type_usado.upper()}**: "
                                       f"Min={riesgos.min():.4f}, "
                                       f"Max={riesgos.max():.4f}, "
                                       f"Mean={riesgos.mean():.4f}, "
                                       f"Std={riesgos.std():.4f}, "
                                       f"Median={np.median(riesgos):.4f}")
                                
                                # Mostrar informaci√≥n de debug para verificar que el modelo es diferente
                                if hasattr(st.session_state.predictor.model, 'n_estimators'):
                                    n_estimators = st.session_state.predictor.model.n_estimators
                                    st.info(f"üîç Debug: Modelo {model_type_usado} con {n_estimators} estimadores")
                                
                                # Verificar que hay variabilidad en las predicciones
                                if riesgos.std() < 0.001:
                                    st.warning("‚ö†Ô∏è **Advertencia:** Las predicciones tienen muy poca variabilidad (std < 0.001). "
                                              "Esto podr√≠a indicar que el modelo est√° prediciendo valores muy similares para todas las comunas. "
                                              "Esto es normal si las features hist√≥ricas son muy similares entre comunas o si el modelo tiene un sesgo fuerte.")
                                
                                risk_map = pd.DataFrame({
                                    'comuna': comunas_unicas,
                                    'riesgo_probabilidad': riesgos,
                                    'incendios_historico': historico_comuna['incendios_total'].values,
                                    'area_historica': historico_comuna['area_total'].values
                                })
                                
                                # Guardar tambi√©n el tipo de modelo usado para esta predicci√≥n
                                risk_map['modelo_usado'] = model_type_usado
                                risk_map['task_type'] = task_type_usado
                                
                                st.session_state.risk_map = risk_map
                                st.success(f"‚úÖ Mapa de riesgo generado usando modelo {model_type_usado.upper()}")
                        
                    except Exception as e:
                        st.error(f"Error al generar mapa de riesgo: {str(e)}")
            
            # Mostrar mapa de riesgo
            if st.session_state.risk_map is not None:
                risk_map = st.session_state.risk_map.copy()
                
                # Mostrar informaci√≥n del modelo usado para esta predicci√≥n
                modelo_usado_pred = risk_map.get('modelo_usado', st.session_state.get('model_type', 'desconocido')).iloc[0] if 'modelo_usado' in risk_map.columns else st.session_state.get('model_type', 'desconocido')
                task_usado_pred = risk_map.get('task_type', st.session_state.get('task_type', 'desconocido')).iloc[0] if 'task_type' in risk_map.columns else st.session_state.get('task_type', 'desconocido')
                
                st.info(f"üìä Mapa de riesgo generado con modelo **{modelo_usado_pred.upper()}** ({task_usado_pred})")
                
                # Eliminar columnas de metadatos para mostrar
                columnas_mostrar = ['comuna', 'riesgo_probabilidad', 'incendios_historico', 'area_historica']
                
                st.subheader("üìã Riesgo por Comuna")
                try:
                    risk_map_sorted = risk_map.sort_values('riesgo_probabilidad', ascending=False)
                    risk_map_sorted['riesgo_categoria'] = pd.cut(
                        risk_map_sorted['riesgo_probabilidad'],
                        bins=[0, 0.3, 0.6, 1.0],
                        labels=['Bajo', 'Medio', 'Alto']
                    )
                    
                    # Filtrar columnas para mostrar (excluir metadatos)
                    columnas_display = [col for col in ['comuna', 'riesgo_probabilidad', 'riesgo_categoria', 'incendios_historico', 'area_historica'] if col in risk_map_sorted.columns]
                    
                    st.dataframe(
                        risk_map_sorted[columnas_display].head(20),
                        width='stretch'
                    )
                    
                    fig_risk = px.bar(
                        risk_map_sorted.head(20),
                        x='riesgo_probabilidad',
                        y='comuna',
                        orientation='h',
                        title='Top 20 Comunas con Mayor Riesgo',
                        labels={'riesgo_probabilidad': 'Probabilidad de Riesgo'},
                        color='riesgo_probabilidad',
                        color_continuous_scale='Reds'
                    )
                    fig_risk.update_layout(yaxis={'categoryorder': 'total ascending'})
                    st.plotly_chart(fig_risk, width='stretch')
                except Exception as e:
                    st.error(f"Error al mostrar mapa de riesgo: {e}")
        else:
            st.warning("""
            ‚ö†Ô∏è **No hay modelo entrenado**
            
            Para hacer predicciones:
            1. Ve a la secci√≥n "Entrenamiento" arriba
            2. Selecciona el tipo de modelo (XGBoost, LightGBM o Random Forest) y tarea (Clasificaci√≥n o Regresi√≥n)
            3. Haz clic en "üöÄ Entrenar Modelo"
            4. Una vez entrenado, podr√°s generar mapas de riesgo aqu√≠
            
            **üí° Nota**: El modelo se entrena con los datos que filtres en la barra lateral (a√±os, regi√≥n, comuna). 
            El modelo se guarda en tu sesi√≥n de navegador y se pierde al cerrar la pesta√±a.
            """)

# ===== TAB 3: Optimizaci√≥n de Recursos =====
with tab3:
    st.header("üéØ Optimizaci√≥n de Asignaci√≥n de Recursos")
    
    if st.session_state.risk_map is None:
        st.warning("‚ö†Ô∏è Por favor genera un mapa de riesgo primero en la pesta√±a 'Predicci√≥n de Riesgo'")
    else:
        region_str = ", ".join(regiones_seleccionadas) if len(regiones_seleccionadas) > 0 else "Todas las Regiones"
        comuna_str = ", ".join(comunas_seleccionadas[:2]) if len(comunas_seleccionadas) > 0 else "Todas las Comunas"
        if len(comunas_seleccionadas) > 2:
            comuna_str += f" (+{len(comunas_seleccionadas)-2} m√°s)"
        st.info(f"üéØ Optimizando recursos para {region_str} ({comuna_str})")
        
        st.subheader("Configuraci√≥n de Optimizaci√≥n")
        
        # Explicaci√≥n sobre optimizaci√≥n
        with st.expander("‚ÑπÔ∏è ¬øQu√© hace la optimizaci√≥n de recursos?", expanded=False):
            st.markdown("""
            **üéØ Objetivo de la Optimizaci√≥n:**
            
            Dado un n√∫mero limitado de brigadas y bases de operaciones, el sistema
            calcula la **mejor ubicaci√≥n** para minimizar el da√±o esperado o el tiempo
            de respuesta.
            
            **üìä C√≥mo funciona:**
            1. Usa el mapa de riesgo generado previamente
            2. Considera la distancia entre bases y zonas de riesgo
            3. Optimiza matem√°ticamente la asignaci√≥n
            4. Genera recomendaciones de ubicaci√≥n √≥ptima
            
            **üí° Casos de uso:**
            - Planificaci√≥n estrat√©gica antes de la temporada de incendios
            - Reubicaci√≥n de recursos durante emergencias
            - Evaluaci√≥n de nuevas ubicaciones de bases
            - Optimizaci√≥n de presupuesto y recursos
            """)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            max_brigades = st.number_input(
                "M√°ximo de Brigadas Disponibles",
                min_value=1,
                max_value=500,
                value=50,
                step=5,
                help="N√∫mero total de brigadas que puedes desplegar"
            )
        
        with col2:
            max_bases = st.number_input(
                "M√°ximo de Bases Posibles",
                min_value=1,
                max_value=50,
                value=10,
                step=1,
                help="N√∫mero m√°ximo de bases de operaciones a activar"
            )
        
        with col3:
            # Explicaci√≥n de objetivos
            with st.expander("‚ÑπÔ∏è ¬øQu√© objetivo elegir?"):
                st.markdown("""
                **Minimize Damage (Minimizar Da√±o)** - Recomendado:
                - üéØ Minimiza el √°rea quemada esperada
                - ‚úÖ Prioriza zonas de alto riesgo
                - ‚úÖ Ideal para: Planificaci√≥n preventiva
                - üìä Considera: Probabilidad √ó Severidad esperada
                
                **Minimize Response Time (Minimizar Tiempo de Respuesta)**:
                - üéØ Minimiza el tiempo promedio de llegada
                - ‚úÖ Prioriza cobertura geogr√°fica
                - ‚úÖ Ideal para: Respuesta r√°pida a emergencias
                - üìä Considera: Distancia √ó Riesgo
                """)
            
            objective = st.selectbox(
                "Objetivo de Optimizaci√≥n",
                ["minimize_damage", "minimize_response_time"],
                index=0,
                help="Elige qu√© minimizar: da√±o esperado o tiempo de respuesta"
            )
        
        if st.button("‚öôÔ∏è Optimizar Asignaci√≥n", type="primary", use_container_width=True):
            with st.spinner("Optimizando asignaci√≥n de recursos..."):
                try:
                    optimizer = ResourceAllocationOptimizer(
                        max_brigades=max_brigades,
                        max_bases=max_bases
                    )
                    
                    optimizer.prepare_data(st.session_state.risk_map)
                    solution = optimizer.optimize(objective=objective)
                    
                    st.session_state.optimizer = optimizer
                    st.session_state.optimizer.solution = solution
                    
                    st.success("‚úÖ Optimizaci√≥n completada")
                    
                    st.subheader("üìä Resultados de la Optimizaci√≥n")
                    
                    col_r1, col_r2, col_r3, col_r4 = st.columns(4)
                    
                    with col_r1:
                        st.metric("Bases Activas", solution['total_bases_activas'])
                    
                    with col_r2:
                        st.metric("Total Brigadas", solution['total_brigades'])
                    
                    with col_r3:
                        st.metric("Tiempo Respuesta Promedio", f"{solution['tiempo_respuesta_promedio']:.1f} min")
                    
                    with col_r4:
                        st.metric("Tiempo Respuesta Ponderado", f"{solution['tiempo_respuesta_ponderado']:.1f} min")
                    
                    st.subheader("üè† Distribuci√≥n de Brigadas por Base")
                    try:
                        brigadas_df = pd.DataFrame(
                            list(solution['brigadas_por_base'].items()),
                            columns=['Base', 'Brigadas']
                        ).sort_values('Brigadas', ascending=False)
                        
                        st.dataframe(brigadas_df, width='stretch')
                        
                        fig_brigadas = px.bar(
                            brigadas_df,
                            x='Base',
                            y='Brigadas',
                            title='Brigadas por Base',
                            color='Brigadas',
                            color_continuous_scale='Greens'
                        )
                        st.plotly_chart(fig_brigadas, width='stretch')
                    except Exception as e:
                        st.error(f"Error al mostrar distribuci√≥n: {e}")
                    
                    st.subheader("üó∫Ô∏è Mapa de Asignaci√≥n")
                    try:
                        allocation_map = optimizer.get_allocation_map()
                        st.dataframe(allocation_map.head(30), width='stretch', height=400)
                    except Exception as e:
                        st.error(f"Error al generar mapa: {e}")
                        
                except Exception as e:
                    st.error(f"Error en optimizaci√≥n: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())

# ===== TAB 4: Reportes y Estad√≠sticas =====
with tab4:
    st.header("üìà Reportes y Estad√≠sticas Avanzadas")
    
    if len(df_filtrado) == 0:
        st.warning("‚ö†Ô∏è Por favor selecciona datos v√°lidos usando los filtros")
    else:
        try:
            st.subheader("üìä An√°lisis Temporal")
            
            col1, col2 = st.columns(2)
            
            with col1:
                incendios_anuales = df_filtrado.groupby('anio')['num_incendios'].sum().reset_index()
                z = np.polyfit(incendios_anuales['anio'], incendios_anuales['num_incendios'], 1)
                p = np.poly1d(z)
                incendios_anuales['tendencia'] = p(incendios_anuales['anio'])
                
                fig_tendencia = go.Figure()
                fig_tendencia.add_trace(go.Scatter(
                    x=incendios_anuales['anio'],
                    y=incendios_anuales['num_incendios'],
                    mode='lines+markers',
                    name='Incendios',
                    line=dict(color='red', width=2)
                ))
                fig_tendencia.add_trace(go.Scatter(
                    x=incendios_anuales['anio'],
                    y=incendios_anuales['tendencia'],
                    mode='lines',
                    name='Tendencia',
                    line=dict(color='blue', dash='dash', width=2)
                ))
                fig_tendencia.update_layout(
                    title='Tendencia de Incendios por A√±o',
                    xaxis_title='A√±o',
                    yaxis_title='N√∫mero de Incendios'
                )
                st.plotly_chart(fig_tendencia, width='stretch')
            
            with col2:
                if len(regiones_seleccionadas) == 0:
                    # Filtrar 'Sin Regi√≥n' y valores inv√°lidos antes de agrupar
                    # Normalizar a may√∫sculas para comparaci√≥n
                    df_region_clean = df_filtrado[
                        (df_filtrado['region'].notna()) & 
                        (df_filtrado['region'].astype(str).str.upper() != 'SIN REGI√ìN') &
                        (df_filtrado['region'].astype(str).str.upper() != 'SIN REGION') &
                        (df_filtrado['region'].astype(str).str.upper() != 'SIN REGI√≥N') &
                        (df_filtrado['region'] != 'Sin Regi√≥n') &
                        (df_filtrado['region'].astype(str) != 'nan') &
                        (df_filtrado['region'].astype(str) != 'NAN')
                    ].copy()
                    
                    if len(df_region_clean) > 0:
                        incendios_region = df_region_clean.groupby('region')['num_incendios'].sum().reset_index()
                        incendios_region = incendios_region.sort_values('num_incendios', ascending=False).head(10)
                        
                        if len(incendios_region) > 0:
                            fig_region = px.bar(
                                incendios_region,
                                x='num_incendios',
                                y='region',
                                orientation='h',
                                title='Top 10 Regiones con M√°s Incendios',
                                labels={'num_incendios': 'N√∫mero de Incendios', 'region': 'Regi√≥n'},
                                color='num_incendios',
                                color_continuous_scale='Reds'
                            )
                            fig_region.update_layout(yaxis={'categoryorder': 'total ascending'})
                            st.plotly_chart(fig_region, width='stretch')
                        else:
                            st.info("No hay datos de regiones v√°lidas para mostrar")
                    else:
                        st.warning("‚ö†Ô∏è Todos los registros tienen regi√≥n 'Sin Regi√≥n' o NaN. Verifica los datos.")
                else:
                    comunas_region = df_filtrado.groupby('comuna')['num_incendios'].sum().reset_index()
                    comunas_region = comunas_region.sort_values('num_incendios', ascending=False).head(10)
                    
                    region_title = ", ".join(regiones_seleccionadas[:2]) if len(regiones_seleccionadas) > 0 else "Todas las Regiones"
                    if len(regiones_seleccionadas) > 2:
                        region_title += f" (+{len(regiones_seleccionadas)-2} m√°s)"
                    fig_comuna = px.bar(
                        comunas_region,
                        x='num_incendios',
                        y='comuna',
                        orientation='h',
                        title=f'Top 10 Comunas con M√°s Incendios ({region_title})',
                        labels={'num_incendios': 'N√∫mero de Incendios'},
                        color='num_incendios',
                        color_continuous_scale='Oranges'
                    )
                    fig_comuna.update_layout(yaxis={'categoryorder': 'total ascending'})
                    st.plotly_chart(fig_comuna, width='stretch')
            
            st.subheader("üìã Estad√≠sticas Descriptivas")
            try:
                stats_df = df_filtrado.groupby('comuna').agg({
                    'num_incendios': ['sum', 'mean', 'std', 'min', 'max'],
                    'area_quemada_ha': ['sum', 'mean']
                }).reset_index()
                
                stats_df.columns = ['Comuna', 'Total Incendios', 'Promedio', 'Desv. Est.', 'M√≠nimo', 'M√°ximo', 
                               '√Årea Total (ha)', '√Årea Promedio (ha)']
                
                st.dataframe(
                    stats_df.sort_values('Total Incendios', ascending=False).head(20),
                    width='stretch',
                    height=400
                )
            except Exception as e:
                st.error(f"Error al generar estad√≠sticas: {e}")
            
            st.subheader("üíæ Exportar Datos")
            try:
                csv = df_filtrado.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="üì• Descargar Datos Filtrados (CSV)",
                    data=csv,
                    file_name=f"incendios_conaf_{ano_inicio}_{ano_fin}_{'_'.join(regiones_seleccionadas[:2]) if len(regiones_seleccionadas) > 0 else 'todas'}.csv",
                    mime="text/csv"
                )
            except Exception as e:
                st.error(f"Error al exportar: {e}")
        
        except Exception as e:
            st.error(f"Error en reportes: {e}")
            import traceback
            st.code(traceback.format_exc())

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
    <p><strong>Sistema de Predicci√≥n y Optimizaci√≥n de Recursos para Incendios Forestales - Chile</strong></p>
    <p>Datos oficiales de CONAF (1985-2024) | Desarrollado con Streamlit</p>
    </div>
    """,
    unsafe_allow_html=True
)
